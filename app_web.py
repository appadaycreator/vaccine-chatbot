import os

import ollama
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter

# ãƒšãƒ¼ã‚¸ã®è¨­å®š
st.set_page_config(page_title="ãƒ¯ã‚¯ãƒãƒ³æ¥ç¨®å¾Œå¥åº·è¦³å¯Ÿã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ", page_icon="ğŸ¥")
st.title("ğŸ¥ å¥åº·è¦³å¯Ÿã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
st.caption("åšåŠ´çœã®å®Ÿæ–½è¦é ˜ã«åŸºã¥ã„ãŸãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆè¨­å®šï¼‰
with st.sidebar:
    st.header("è¨­å®š")
    llm_model = st.selectbox("å›ç­”ãƒ¢ãƒ‡ãƒ«", ["gemma2", "llama3.1"], index=0)
    k = st.slider("æ¤œç´¢ã®å¼·ã•ï¼ˆkå€¤ï¼‰", min_value=1, max_value=10, value=3, step=1)
    st.caption("åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«: `nomic-embed-text`ï¼ˆå›ºå®šï¼‰")
    st.caption("PDFã¯ã‚µãƒ¼ãƒãƒ¼å´ã§ `./pdfs/`ï¼ˆç’°å¢ƒå¤‰æ•° `PDF_DIR`ï¼‰ã«é…ç½®ã—ã¦åˆ©ç”¨ã—ã¾ã™ã€‚")


def _normalize_docs_source(docs, source_label: str):
    for d in docs:
        d.metadata = dict(d.metadata or {})
        d.metadata["source"] = source_label
    return docs


@st.cache_resource(show_spinner=False)
def _build_vectorstore_from_paths(paths: list[str], signature: str):
    # signature ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼å®‰å®šåŒ–ã®ãŸã‚
    chunks = []
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    for p in paths:
        loader = PyPDFLoader(p)
        docs = loader.load()
        docs = _normalize_docs_source(docs, os.path.basename(p))
        chunks.extend([c for c in splitter.split_documents(docs) if (c.page_content or "").strip()])
    embeddings = OllamaEmbeddings(model="nomic-embed-text")
    return Chroma.from_documents(documents=chunks, embedding=embeddings)


def _list_pdf_paths() -> list[str]:
    pdf_dir = os.environ.get("PDF_DIR", "./pdfs")
    pdf_path = os.environ.get("PDF_PATH", "vaccine_manual.pdf")
    paths: list[str] = []
    if pdf_path and os.path.exists(pdf_path) and pdf_path.lower().endswith(".pdf"):
        paths.append(pdf_path)
    try:
        if pdf_dir and os.path.isdir(pdf_dir):
            for f in sorted(os.listdir(pdf_dir)):
                if f.lower().endswith(".pdf"):
                    paths.append(os.path.join(pdf_dir, f))
    except Exception:
        pass
    # é‡è¤‡é™¤å»
    uniq: list[str] = []
    seen: set[str] = set()
    for p in paths:
        ap = os.path.abspath(p)
        if ap in seen:
            continue
        seen.add(ap)
        uniq.append(p)
    return uniq


def _signature(paths: list[str]) -> str:
    parts: list[str] = []
    for p in paths:
        try:
            st_ = os.stat(p)
            parts.append(f"{os.path.abspath(p)}|{int(st_.st_size)}|{float(st_.st_mtime)}")
        except Exception:
            parts.append(f"{os.path.abspath(p)}|NA|NA")
    return "\n".join(sorted(parts))

paths = _list_pdf_paths()
try:
    if not paths:
        st.error("å‚ç…§ã™ã‚‹PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚`vaccine_manual.pdf` ã¾ãŸã¯ `./pdfs/` ã«PDFã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    sig = _signature(paths)
    with st.spinner("PDFã‚’è§£æã—ã¦çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ä¸­...ï¼ˆåˆå›ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰"):
        vectorstore = _build_vectorstore_from_paths(paths, sig)
    st.success(f"è³‡æ–™ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆ{len(paths)}ä»¶ï¼‰ã€‚")
except Exception as e:
    st.error(f"PDFã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ: {e}")
    st.stop()

# ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
col1, col2 = st.columns([1, 3])
with col1:
    if st.button("å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ"):
        st.session_state.messages = []
        st.rerun()

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

# å±¥æ­´ã®è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if message["role"] == "assistant" and message.get("sources"):
            sources = message["sources"]
            pages = []
            for s in sources:
                if s.get("page") is not None:
                    pages.append(f"{s.get('source','è³‡æ–™')} p.{s['page']}")
                else:
                    pages.append(f"{s.get('source','è³‡æ–™')}")
            st.markdown("**æ ¹æ‹ ï¼ˆå‚ç…§ãƒšãƒ¼ã‚¸ï¼‰**: " + " / ".join(pages))
            with st.expander("æ ¹æ‹ ã®æŠœç²‹ã‚’è¡¨ç¤º"):
                for s in sources:
                    title = f"{s.get('source','è³‡æ–™')}"
                    if s.get("page") is not None:
                        title += f" p.{s['page']}"
                    st.markdown(f"- {title}")
                    if s.get("excerpt"):
                        st.caption(s["excerpt"])


def _extract_sources(docs):
    sources = []
    seen = set()
    for d in docs:
        meta = d.metadata or {}
        src = meta.get("source") or "è³‡æ–™"
        page = meta.get("page")
        page_num = page + 1 if isinstance(page, int) else None
        key = (src, page_num)
        if key in seen:
            continue
        seen.add(key)
        excerpt = (d.page_content or "").strip().replace("\n", " ")
        if len(excerpt) > 400:
            excerpt = excerpt[:400] + "â€¦"
        sources.append({"source": src, "page": page_num, "excerpt": excerpt})
    return sources

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
if prompt := st.chat_input("è³ªå•ã‚’ã©ã†ã"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # RAGãƒ­ã‚¸ãƒƒã‚¯
    with st.chat_message("assistant"):
        with st.spinner("è³‡æ–™ã‚’ç¢ºèªä¸­..."):
            # æ¤œç´¢
            docs = vectorstore.similarity_search(prompt, k=k)
            context = "\n".join([doc.page_content for doc in docs])
            sources = _extract_sources(docs)
            
            # ç”Ÿæˆ
            full_prompt = f"""
ã‚ãªãŸã¯åšåŠ´çœã®è³‡æ–™ã«åŸºã¥ã„ã¦å›ç­”ã™ã‚‹å°‚é–€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ã€è³‡æ–™æŠœç²‹ã€‘ã®å†…å®¹ã«åŸºã¥ã„ã¦ã€æ—¥æœ¬èªã§ç°¡æ½”ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
è³‡æ–™ã«è¨˜è¼‰ãŒãªã„å ´åˆã¯ã€Œè³‡æ–™å†…ã«ã¯è©²å½“ã™ã‚‹æƒ…å ±ãŒè¦‹å½“ãŸã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã€è‡ªæ²»ä½“ã®ç›¸è«‡çª“å£ã¾ãŸã¯æ¥ç¨®ã‚’å—ã‘ãŸåŒ»ç™‚æ©Ÿé–¢ã¸ã®ç›¸è«‡ã‚’ä¿ƒã—ã¦ãã ã•ã„ã€‚

ã€è³‡æ–™æŠœç²‹ã€‘
{context}

è³ªå•: {prompt}
å›ç­”:
""".strip()
            response = ollama.generate(model=llm_model, prompt=full_prompt)
            answer = response['response']
            
            st.markdown(answer)
            if sources:
                pages = []
                for s in sources:
                    if s.get("page") is not None:
                        pages.append(f"{s.get('source','è³‡æ–™')} p.{s['page']}")
                    else:
                        pages.append(f"{s.get('source','è³‡æ–™')}")
                st.markdown("**æ ¹æ‹ ï¼ˆå‚ç…§ãƒšãƒ¼ã‚¸ï¼‰**: " + " / ".join(pages))
                with st.expander("æ ¹æ‹ ã®æŠœç²‹ã‚’è¡¨ç¤º"):
                    for s in sources:
                        title = f"{s.get('source','è³‡æ–™')}"
                        if s.get("page") is not None:
                            title += f" p.{s['page']}"
                        st.markdown(f"- {title}")
                        if s.get("excerpt"):
                            st.caption(s["excerpt"])

            st.session_state.messages.append({"role": "assistant", "content": answer, "sources": sources})